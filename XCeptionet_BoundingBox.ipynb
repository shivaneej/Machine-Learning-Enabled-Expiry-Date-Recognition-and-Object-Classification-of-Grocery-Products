{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqkKfEit4_yC"
      },
      "source": [
        "# Bounding Box Regression\n",
        "[PyImageSearch | Object detection: Bounding box regression with Keras, TensorFlow, and Deep Learning](https://pyimagesearch.com/2020/10/05/object-detection-bounding-box-regression-with-keras-tensorflow-and-deep-learning/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulXKoLrJH5Vo"
      },
      "source": [
        "## Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ehGRHxe5NL-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc_ZyC_Ohh3i"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLfft5798OYR"
      },
      "outputs": [],
      "source": [
        "# define the base path to the input dataset and then use it to derive\n",
        "# the path to the images directory and annotation CSV file\n",
        "BASE_PATH = \"/content/drive/MyDrive/ML_Project/Data/BoundingBoxTraining\"\n",
        "IMAGES_PATH = os.path.sep.join([BASE_PATH, \"images\"])\n",
        "ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"annotations.json\"])\n",
        "\n",
        "# define the path to the base output directory\n",
        "BASE_OUTPUT = \"/content/output\"\n",
        "# define the path to the output serialized model, model training plot,\n",
        "# and testing image filenames\n",
        "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"detector.h5\"])\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "TEST_FILENAMES = os.path.sep.join([BASE_OUTPUT, \"test_images.txt\"])\n",
        "\n",
        "# initialize our initial learning rate, number of epochs to train\n",
        "# for, and the batch size\n",
        "INIT_LR = 4e-4\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IvCuIiLClzu"
      },
      "outputs": [],
      "source": [
        "os.mkdir(BASE_OUTPUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ3kIMbp9s6J"
      },
      "outputs": [],
      "source": [
        "# load the contents of the CSV annotations file\n",
        "print(\"[INFO] loading dataset...\")\n",
        "json_data = json.load(open(ANNOTS_PATH))\n",
        "# initialize the list of data (images), our target output predictions\n",
        "# (bounding box coordinates), along with the filenames of the\n",
        "# individual images\n",
        "data = []\n",
        "targets = []\n",
        "filenames = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Sh-5fMI-VLU"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "Multiple annotations are present in the diff row\n",
        "'''\n",
        "for key, value in list(json_data.items()):\n",
        "  filename = key\n",
        "  bboxes = []\n",
        "  imagePath = os.path.sep.join([IMAGES_PATH, filename])\n",
        "  if not os.path.exists(imagePath):\n",
        "    break\n",
        "  # print(imagePath)\n",
        "  image = cv2.imread(imagePath)\n",
        "  (h, w) = image.shape[:2]\n",
        "  # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image,(224, 224))\n",
        "  # image = cv2.erode(image, None, iterations=1)\n",
        "  image = img_to_array(image)\n",
        "  for ann in value['ann']:\n",
        "    if ann['cls'] == 'date':\n",
        "      startX, startY, endX, endY = ann['bbox']\n",
        "      startX = float(startX) / w\n",
        "      startY = float(startY) / h\n",
        "      endX = float(endX) / w\n",
        "      endY = float(endY) / h\n",
        "      bboxes.append([startX, startY, endX, endY])\n",
        "      data.append(image)\n",
        "      targets.append((startX, startY, endX, endY))\n",
        "      filenames.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1exho5_GUZ_",
        "outputId": "fe651d53-6184-43e3-a155-3a300589a077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] saving testing filenames...\n"
          ]
        }
      ],
      "source": [
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "targets = np.array(targets, dtype=\"float32\")\n",
        "# partition the data into training and testing splits using 90% of\n",
        "# the data for training and the remaining 10% for testing\n",
        "split = train_test_split(data, targets, filenames, test_size=0.10,\n",
        "\trandom_state=42)\n",
        "# unpack the data split\n",
        "(trainImages, testImages) = split[:2]\n",
        "(trainTargets, testTargets) = split[2:4]\n",
        "(trainFilenames, testFilenames) = split[4:]\n",
        "# write the testing filenames to disk so that we can use then\n",
        "# when evaluating/testing our bounding box regressor\n",
        "print(\"[INFO] saving testing filenames...\")\n",
        "f = open(TEST_FILENAMES, \"w\")\n",
        "f.write(\"\\n\".join(testFilenames))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDijAloxH8PH"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8ycFz36Cw1e"
      },
      "outputs": [],
      "source": [
        "pip install tf-explain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkWGJqblCw4g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tf_explain.core.activations import ExtractActivations\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications.xception import decode_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm_qM0_HHAJq"
      },
      "outputs": [],
      "source": [
        "\n",
        "xcept = InceptionV3(input_tensor= Input(shape=(224, 224, 3)), weights='imagenet', include_top=False)\n",
        "\n",
        "# xcept = tf.keras.applications.xception.Xception(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "# freeze all VGG layers so they will *not* be updated during the\n",
        "# training process\n",
        "xcept.trainable = False\n",
        "# flatten the max-pooling output of VGG\n",
        "flatten = xcept.output\n",
        "flatten = Flatten()(flatten)\n",
        "# construct a fully-connected layer header to output the predicted\n",
        "# bounding box coordinates\n",
        "bboxHead = Dense(16, activation=\"relu\")(flatten)\n",
        "# bboxHead = Dropout(0.5)(bboxHead)\n",
        "# # //bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "# # bboxHead = Dropout(0.5)(bboxHead)\n",
        "# bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "# # bboxHead = Dropout(0.5)(bboxHead)\n",
        "# bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "# # bboxHead = Dropout(0.5)(bboxHead)\n",
        "# bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dropout(0.5)(bboxHead)\n",
        "bboxHead = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
        "# construct the model we will fine-tune for bounding box regression\n",
        "model = Model(inputs=xcept.input, outputs=bboxHead)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x3jU3UYFRU7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBLv8r8VFVR5"
      },
      "outputs": [],
      "source": [
        "INIT_LR = 4e-4\n",
        "NUM_EPOCHS = 30\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKWr_S3eHIF0"
      },
      "outputs": [],
      "source": [
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqlG9TfDHFS8"
      },
      "outputs": [],
      "source": [
        "# initialize the optimizer, compile the model, and show the model\n",
        "# summary\n",
        "model.compile(loss=\"mse\", optimizer= tensorflow.keras.optimizers.Adam(), metrics=[\n",
        "        'MeanSquaredError',  'accuracy'\n",
        "    ])\n",
        "print(model.summary())\n",
        "# train the network for bounding box regression\n",
        "print(\"[INFO] training bounding box regressor...\")\n",
        "H = model.fit(\n",
        "\ttrainImages, trainTargets,\n",
        "\tvalidation_data=(testImages, testTargets),\n",
        "\tbatch_size=BATCH_SIZE,\n",
        "\tepochs=10,\n",
        "\tverbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E6KUXLvHWJh"
      },
      "outputs": [],
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving object detector model...\")\n",
        "model.save(MODEL_PATH, save_format=\"h5\")\n",
        "# plot the model training history\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(PLOT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPrkYa4BH0SM"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wXHetDuIB6K"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import mimetypes\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84w_Zd8dOGD6"
      },
      "outputs": [],
      "source": [
        "# test_image = '/content/drive/MyDrive/ML_Project/Data/BoundingBoxTraining/images/img_00010.jpg'\n",
        "test_image = '/content/output/test_images.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4CScGyKIKWm",
        "outputId": "2c6139c8-e885-4140-f9a7-562e1a70d779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/output/test_images.txt\n"
          ]
        }
      ],
      "source": [
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--input\", required=False,\n",
        "\thelp=\"path to input image/text file of image filenames\", default=test_image)\n",
        "# args = vars(ap.parse_args())\n",
        "args = ap.parse_args(args=[])\n",
        "print(args.input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpeiBI04NSzs"
      },
      "outputs": [],
      "source": [
        "# determine the input file type, but assume that we're working with\n",
        "# single input image\n",
        "filetype = mimetypes.guess_type(args.input)[0]\n",
        "print(filetype)\n",
        "imagePaths = [args.input]\n",
        "# if the file type is a text file, then we need to process *multiple*\n",
        "# images\n",
        "if \"text/plain\" == filetype:\n",
        "\t# load the filenames in our testing file and initialize our list\n",
        "\t# of image paths\n",
        "\tfilenames = open(args.input).read().strip().split(\"\\n\")\n",
        "\timagePaths = []\n",
        "\t# loop over the filenames\n",
        "\tfor f in filenames:\n",
        "\t\t# construct the full path to the image filename and then\n",
        "\t\t# update our image paths list\n",
        "\t\tp = os.path.sep.join([IMAGES_PATH, f])\n",
        "\t\timagePaths.append(p)\n",
        "print(imagePaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvyCo_wTQnKA"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OoFLH-PSQNKU"
      },
      "outputs": [],
      "source": [
        "print(\"[INFO] loading object detector...\")\n",
        "model = load_model(MODEL_PATH)\n",
        "# loop over the images that we'll be testing using our bounding box\n",
        "# regression model\n",
        "for imagePath in imagePaths:\n",
        "\t# load the input image (in Keras format) from disk and preprocess\n",
        "\t# it, scaling the pixel intensities to the range [0, 1]\n",
        "  image = cv2.imread(imagePath)\n",
        "  (h, w) = image.shape[:2]\n",
        "  # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image,(224, 224))\n",
        "  # image = cv2.erode(image, None, iterations=1)\n",
        "  image = img_to_array(image) / 255.0\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  # make bounding box predictions on the input image\n",
        "  preds = model.predict(image)[0]\n",
        "  (startX, startY, endX, endY) = preds\n",
        "  # load the input image (in OpenCV format), resize it such that it\n",
        "  # fits on our screen, and grab its dimensions\n",
        "  image = cv2.imread(imagePath)\n",
        "  image = imutils.resize(image, width=600)\n",
        "  (h, w) = image.shape[:2]\n",
        "  print(h,w)\n",
        "  # scale the predicted bounding box coordinates based on the image\n",
        "  # dimensions\n",
        "  startX = int(startX * w)\n",
        "  startY = int(startY * h)\n",
        "  endX = int(endX * w)\n",
        "  endY = int(endY * h)\n",
        "  # show the output image\n",
        "  cv2_imshow(image)\n",
        "  # show the output image\n",
        "  print(image.shape)\n",
        "  bb = image[startY-10:endY+10, startX-10: endX+10]\n",
        "  # cv2.imwrite('/content/output/test.png', bb)\n",
        "  cv2_imshow(bb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO__t2laQRzu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1BiwJHp47rX"
      },
      "source": [
        "# Data Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWWZIE33Fcmm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow \n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSVtW7wwF5Sb"
      },
      "outputs": [],
      "source": [
        "img_path = '/content/img_00001.jpg'\n",
        "img = cv2.imread(img_path)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SktBVgbeGHp6"
      },
      "outputs": [],
      "source": [
        "annotation_path = '/content/annotations.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYNEdGa1FNDJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "  \n",
        "def show_image_with_bounding_box(image_path, annotation_path):\n",
        "  img = cv2.imread(image_path)\n",
        "  json_data = json.load(open(annotation_path))\n",
        "  filename = image_path.split('/')[-1]\n",
        "  data = json_data[filename]['ann']\n",
        "  # plt.imshow(img)\n",
        "  for a in data:\n",
        "    bbox = a['bbox']\n",
        "    cls = a['cls']\n",
        "    x1 = int(bbox[0])\n",
        "    y1 = int(bbox[1])\n",
        "    x2 = int(bbox[2])\n",
        "    y2 = int(bbox[3])\n",
        "    if cls == 'date':\n",
        "      cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0), 2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "  scale_percent = 220 # percent of original size\n",
        "  width = int(img.shape[1] * scale_percent / 100)\n",
        "  height = int(img.shape[0] * scale_percent / 100)\n",
        "  dim = (width, height)\n",
        "  \n",
        "  resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.imshow(resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvPV6HqjKCcg"
      },
      "outputs": [],
      "source": [
        "ROOT = '/content/images'\n",
        "all_images = []\n",
        "for path in os.listdir(ROOT):\n",
        "  if os.path.isfile(os.path.join(ROOT, path)):\n",
        "    all_images.append(os.path.join(ROOT, path))\n",
        "print(all_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCbt6Pf0GhYi"
      },
      "outputs": [],
      "source": [
        "for img_path in all_images:\n",
        "  show_image_with_bounding_box(img_path, annotation_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPmwTCcp_ii7"
      },
      "outputs": [],
      "source": [
        "/content/output/detector.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSesg3A8icxh"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZoylUbSielx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "t1BiwJHp47rX"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}